{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andre\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact_manual\n",
    "import os\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical,Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>Свердловская область</td>\n",
       "      <td>Екатеринбург</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>Private</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.12789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>Самарская область</td>\n",
       "      <td>Самара</td>\n",
       "      <td>Для дома и дачи</td>\n",
       "      <td>Мебель и интерьер</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>Private</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>Ростовская область</td>\n",
       "      <td>Ростов-на-Дону</td>\n",
       "      <td>Бытовая электроника</td>\n",
       "      <td>Аудио и видео</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>Private</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>0.43177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>Татарстан</td>\n",
       "      <td>Набережные Челны</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Товары для детей и игрушки</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>Company</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.80323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>Волгоградская область</td>\n",
       "      <td>Волгоград</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>Private</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.20797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id                 region              city  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9   Свердловская область      Екатеринбург   \n",
       "1  2dac0150717d  39aeb48f0017      Самарская область            Самара   \n",
       "2  ba83aefab5dc  91e2f88dd6e3     Ростовская область    Ростов-на-Дону   \n",
       "3  02996f1dd2ea  bf5cccea572d              Татарстан  Набережные Челны   \n",
       "4  7c90be56d2ab  ef50846afc0b  Волгоградская область         Волгоград   \n",
       "\n",
       "  parent_category_name               category_name  \\\n",
       "0          Личные вещи  Товары для детей и игрушки   \n",
       "1      Для дома и дачи           Мебель и интерьер   \n",
       "2  Бытовая электроника               Аудио и видео   \n",
       "3          Личные вещи  Товары для детей и игрушки   \n",
       "4            Транспорт                  Автомобили   \n",
       "\n",
       "                       param_1     param_2 param_3                  title  \\\n",
       "0    Постельные принадлежности         NaN     NaN  Кокоби(кокон для сна)   \n",
       "1                       Другое         NaN     NaN      Стойка для Одежды   \n",
       "2  Видео, DVD и Blu-ray плееры         NaN     NaN         Philips bluray   \n",
       "3         Автомобильные кресла         NaN     NaN             Автокресло   \n",
       "4                   С пробегом  ВАЗ (LADA)    2110         ВАЗ 2110, 2003   \n",
       "\n",
       "                                         description    price  \\\n",
       "0  Кокон для сна малыша,пользовались меньше месяц...    400.0   \n",
       "1          Стойка для одежды, под вешалки. С бутика.   3000.0   \n",
       "2  В хорошем состоянии, домашний кинотеатр с blu ...   4000.0   \n",
       "3                             Продам кресло от0-25кг   2200.0   \n",
       "4                           Все вопросы по телефону.  40000.0   \n",
       "\n",
       "   item_seq_number activation_date user_type  \\\n",
       "0                2      2017-03-28   Private   \n",
       "1               19      2017-03-26   Private   \n",
       "2                9      2017-03-20   Private   \n",
       "3              286      2017-03-25   Company   \n",
       "4                3      2017-03-16   Private   \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...       3032.0   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...        796.0   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...       2264.0   \n",
       "\n",
       "   deal_probability  \n",
       "0           0.12789  \n",
       "1           0.00000  \n",
       "2           0.43177  \n",
       "3           0.80323  \n",
       "4           0.20797  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = pd.read_csv(\"./input/avito-demand-prediction/train.csv\")\n",
    "\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>category_name</th>\n",
       "      <th>param_1</th>\n",
       "      <th>param_2</th>\n",
       "      <th>param_3</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>deal_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b912c3c6a6ad</td>\n",
       "      <td>e00f8ff2eaf9</td>\n",
       "      <td>19</td>\n",
       "      <td>460</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Постельные принадлежности</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Кокоби(кокон для сна)</td>\n",
       "      <td>Кокон для сна малыша,пользовались меньше месяц...</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-03-28</td>\n",
       "      <td>1</td>\n",
       "      <td>d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>0.12789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2dac0150717d</td>\n",
       "      <td>39aeb48f0017</td>\n",
       "      <td>17</td>\n",
       "      <td>1300</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>Другое</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Стойка для Одежды</td>\n",
       "      <td>Стойка для одежды, под вешалки. С бутика.</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-03-26</td>\n",
       "      <td>1</td>\n",
       "      <td>79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ba83aefab5dc</td>\n",
       "      <td>91e2f88dd6e3</td>\n",
       "      <td>16</td>\n",
       "      <td>1276</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Видео, DVD и Blu-ray плееры</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Philips bluray</td>\n",
       "      <td>В хорошем состоянии, домашний кинотеатр с blu ...</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2017-03-20</td>\n",
       "      <td>1</td>\n",
       "      <td>b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>0.43177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02996f1dd2ea</td>\n",
       "      <td>bf5cccea572d</td>\n",
       "      <td>21</td>\n",
       "      <td>940</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Автомобильные кресла</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Автокресло</td>\n",
       "      <td>Продам кресло от0-25кг</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>286</td>\n",
       "      <td>2017-03-25</td>\n",
       "      <td>0</td>\n",
       "      <td>e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.80323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7c90be56d2ab</td>\n",
       "      <td>ef50846afc0b</td>\n",
       "      <td>4</td>\n",
       "      <td>317</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>С пробегом</td>\n",
       "      <td>ВАЗ (LADA)</td>\n",
       "      <td>2110</td>\n",
       "      <td>ВАЗ 2110, 2003</td>\n",
       "      <td>Все вопросы по телефону.</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-03-16</td>\n",
       "      <td>1</td>\n",
       "      <td>54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...</td>\n",
       "      <td>2264.0</td>\n",
       "      <td>0.20797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_id       user_id  region  city  parent_category_name  \\\n",
       "0  b912c3c6a6ad  e00f8ff2eaf9      19   460                     4   \n",
       "1  2dac0150717d  39aeb48f0017      17  1300                     2   \n",
       "2  ba83aefab5dc  91e2f88dd6e3      16  1276                     0   \n",
       "3  02996f1dd2ea  bf5cccea572d      21   940                     4   \n",
       "4  7c90be56d2ab  ef50846afc0b       4   317                     6   \n",
       "\n",
       "   category_name                      param_1     param_2 param_3  \\\n",
       "0             42    Постельные принадлежности         NaN     NaN   \n",
       "1             22                       Другое         NaN     NaN   \n",
       "2              2  Видео, DVD и Blu-ray плееры         NaN     NaN   \n",
       "3             42         Автомобильные кресла         NaN     NaN   \n",
       "4              0                   С пробегом  ВАЗ (LADA)    2110   \n",
       "\n",
       "                   title                                        description  \\\n",
       "0  Кокоби(кокон для сна)  Кокон для сна малыша,пользовались меньше месяц...   \n",
       "1      Стойка для Одежды          Стойка для одежды, под вешалки. С бутика.   \n",
       "2         Philips bluray  В хорошем состоянии, домашний кинотеатр с blu ...   \n",
       "3             Автокресло                             Продам кресло от0-25кг   \n",
       "4         ВАЗ 2110, 2003                           Все вопросы по телефону.   \n",
       "\n",
       "     price  item_seq_number activation_date  user_type  \\\n",
       "0    400.0                2      2017-03-28          1   \n",
       "1   3000.0               19      2017-03-26          1   \n",
       "2   4000.0                9      2017-03-20          1   \n",
       "3   2200.0              286      2017-03-25          0   \n",
       "4  40000.0                3      2017-03-16          1   \n",
       "\n",
       "                                               image  image_top_1  \\\n",
       "0  d10c7e016e03247a3bf2d13348fe959fe6f436c1caf64c...       1008.0   \n",
       "1  79c9392cc51a9c81c6eb91eceb8e552171db39d7142700...        692.0   \n",
       "2  b7f250ee3f39e1fedd77c141f273703f4a9be59db4b48a...       3032.0   \n",
       "3  e6ef97e0725637ea84e3d203e82dadb43ed3cc0a1c8413...        796.0   \n",
       "4  54a687a3a0fc1d68aed99bdaaf551c5c70b761b16fd0a2...       2264.0   \n",
       "\n",
       "   deal_probability  \n",
       "0           0.12789  \n",
       "1           0.00000  \n",
       "2           0.43177  \n",
       "3           0.80323  \n",
       "4           0.20797  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to one-hot vectors.  \n",
    "trainDF[\"category_name\"] = pd.Categorical(trainDF[\"category_name\"]).codes\n",
    "trainDF[\"city\"] = pd.Categorical(trainDF[\"city\"]).codes\n",
    "trainDF[\"region\"] = pd.Categorical(trainDF[\"region\"]).codes\n",
    "trainDF[\"parent_category_name\"] = pd.Categorical(trainDF[\"parent_category_name\"]).codes\n",
    "trainDF[\"user_type\"] = pd.Categorical(trainDF[\"user_type\"]).codes\n",
    "\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentileOneHot(dealProb,nBuckets=10):\n",
    "    val = math.floor((dealProb*nBuckets))\n",
    "    if dealProb == 1: \n",
    "        val = nBuckets-1\n",
    "        \n",
    "    return val,to_categorical(val , num_classes=nBuckets)\n",
    "\n",
    "percentileRes = trainDF[\"deal_probability\"].map(percentileOneHot) \n",
    "trainDF = trainDF.assign(percentileClassID = percentileRes.apply(lambda x: x[0]), percentileClass = percentileRes.apply(lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training and validation set. \n",
    "trainDF = trainDF.sample(frac=1)\n",
    "\n",
    "nItems = trainDF.shape[0]\n",
    "nValidation = int(nItems * 0.2)\n",
    "\n",
    "validation = trainDF[0:nValidation]\n",
    "train      = trainDF[nValidation:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1202740, 20)\n",
      "(300684, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>category_name</th>\n",
       "      <th>parent_category_name</th>\n",
       "      <th>user_type</th>\n",
       "      <th>image_top_1</th>\n",
       "      <th>item_seq_number</th>\n",
       "      <th>activation_date</th>\n",
       "      <th>deal_probability</th>\n",
       "      <th>descLen</th>\n",
       "      <th>titleLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>962875</th>\n",
       "      <td>8500.0</td>\n",
       "      <td>9</td>\n",
       "      <td>723</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1530.0</td>\n",
       "      <td>68</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>142</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31739</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1589</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2936.0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.27219</td>\n",
       "      <td>130</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213751</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>460</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>505.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391324</th>\n",
       "      <td>5500.0</td>\n",
       "      <td>21</td>\n",
       "      <td>585</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499804</th>\n",
       "      <td>500.0</td>\n",
       "      <td>5</td>\n",
       "      <td>329</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>658.0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>77</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  region  city  category_name  parent_category_name  user_type  \\\n",
       "962875   8500.0       9   723             22                     2          0   \n",
       "31739    3000.0       1  1589             41                     0          1   \n",
       "213751   1000.0      19   460             29                     4          1   \n",
       "391324   5500.0      21   585             22                     2          1   \n",
       "1499804   500.0       5   329             10                     4          1   \n",
       "\n",
       "         image_top_1  item_seq_number  activation_date  deal_probability  \\\n",
       "962875        1530.0               68                4           0.00000   \n",
       "31739         2936.0               39                0           0.27219   \n",
       "213751         505.0               24                0           0.00000   \n",
       "391324        1490.0               12                5           0.00000   \n",
       "1499804        658.0               20                1           0.00000   \n",
       "\n",
       "         descLen  titleLen  \n",
       "962875       142        15  \n",
       "31739        130        13  \n",
       "213751        80        17  \n",
       "391324        50         6  \n",
       "1499804       77        35  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = [\"price\",\"region\",\"city\",\"category_name\",\"parent_category_name\",\n",
    "         \"user_type\",\"title\",\"description\",\"image_top_1\",\"item_seq_number\",\"activation_date\",\"deal_probability\"]\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 200\n",
    "descTokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "def preprocessDat(df):\n",
    "    select = df.dropna()\n",
    "    select = select.assign(descLen = select[\"description\"].map(len))\n",
    "    select = select.assign(titleLen = select[\"title\"].map(len))\n",
    "    select[\"activation_date\"] = pd.to_datetime(select[\"activation_date\"])\n",
    "    select[\"activation_date\"] = select[\"activation_date\"].map(lambda x: x.dayofweek)\n",
    "    \n",
    "    return select\n",
    "\n",
    "# Training Preprocessing \n",
    "select_train = preprocessDat(train[feats])\n",
    "#descTokenizer.fit_on_texts(select_train[\"description\"]) \n",
    "#select_train_desc = pad_sequences(descTokenizer.texts_to_sequences(select_train[\"description\"]),maxlen = maxlen )\n",
    "select_train = select_train.drop([\"description\",\"title\"],axis=1)\n",
    "\n",
    "# Validation Preprocesing\n",
    "select_val = preprocessDat(validation[feats])\n",
    "#select_val_desc = pad_sequences(descTokenizer.texts_to_sequences(select_val[\"description\"]),maxlen = maxlen )\n",
    "select_val = select_val.drop([\"description\",\"title\"],axis=1)\n",
    "\n",
    "scaler = preprocessing.RobustScaler().fit(select_train.drop(\"deal_probability\",axis=1))\n",
    "select_train_scaled = scaler.transform(select_train.drop(\"deal_probability\",axis=1))\n",
    "select_val_scaled   = scaler.transform(select_val.drop(\"deal_probability\",axis=1))\n",
    "\n",
    "select_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSdUMDUlSNUNDklTN0JAkVft/MigUcgcDqagAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23f670c0208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "select_train[\"deal_probability\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvenClassDataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, df, categoricalColumn,targetCol, batch_size=10):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.targetCol = targetCol\n",
    "        self.classes = list(np.sort(df[categoricalColumn].unique()))\n",
    "        self.categories = list(map(lambda x: df[df[categoricalColumn] == x].drop(categoricalColumn,axis=1),self.classes))\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return 1000\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        resultsX  = []\n",
    "        dealProbs = []\n",
    "        \n",
    "        for cat in self.categories:\n",
    "            sample = cat.sample(self.batch_size)\n",
    "            resultsX.append(scaler.transform(sample.drop(self.targetCol,axis=1)))\n",
    "            dealProbs.append(np.vstack(sample[self.targetCol]))\n",
    "            \n",
    "        X = np.vstack(resultsX)\n",
    "        y = np.vstack(dealProbs)\n",
    "        return X, y\n",
    "\n",
    "def percentileOneHot(dealProb,nBuckets=10):\n",
    "    val = math.floor((dealProb*nBuckets))\n",
    "    if dealProb == 1: \n",
    "        val = nBuckets-1\n",
    "    \n",
    "    if val == 0:\n",
    "        pass\n",
    "    elif val in [2,3,4,5,6]:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 2\n",
    "    \n",
    "    return val,to_categorical(val , num_classes=nBuckets)\n",
    "\n",
    "percentileRes = select_train[\"deal_probability\"].map(percentileOneHot) \n",
    "select_train_gen = select_train.assign(percentileClassID = percentileRes.apply(lambda x: x[0]))\n",
    "\n",
    "balancedBatch = EvenClassDataGenerator(select_train_gen,\"percentileClassID\",\"deal_probability\",50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 61,901\n",
      "Trainable params: 61,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Input,BatchNormalization,Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "inp1 = Input(shape=(len(feats)-1, ))\n",
    "x = Dense(100,activation=\"sigmoid\")(inp1)\n",
    "x = Dense(100,activation=\"sigmoid\")(x)\n",
    "x = Dense(100,activation=\"sigmoid\")(x)\n",
    "x = Dense(100,activation=\"sigmoid\")(x)\n",
    "x = Dense(100,activation=\"sigmoid\")(x)\n",
    "x = Dense(100,activation=\"sigmoid\")(x)\n",
    "x = Dense(100,activation=\"sigmoid\")(x)\n",
    "x = Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inp1,x)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=[rmse])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5925 - rmse: 0.2394\n",
      "Epoch 2/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5835 - rmse: 0.2325\n",
      "Epoch 3/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5836 - rmse: 0.2327\n",
      "Epoch 4/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5830 - rmse: 0.2317\n",
      "Epoch 5/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5835 - rmse: 0.2324\n",
      "Epoch 6/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5819 - rmse: 0.23100s - loss: 0.581\n",
      "Epoch 7/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5829 - rmse: 0.2318\n",
      "Epoch 8/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5825 - rmse: 0.2317\n",
      "Epoch 9/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5813 - rmse: 0.2307\n",
      "Epoch 10/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5825 - rmse: 0.2314\n",
      "Epoch 11/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5816 - rmse: 0.2308\n",
      "Epoch 12/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5812 - rmse: 0.2305\n",
      "Epoch 13/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5816 - rmse: 0.23090s - loss: 0.5815 - rmse: 0.23\n",
      "Epoch 14/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5818 - rmse: 0.2311\n",
      "Epoch 15/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5816 - rmse: 0.2308\n",
      "Epoch 16/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5804 - rmse: 0.2298\n",
      "Epoch 17/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5802 - rmse: 0.2294\n",
      "Epoch 18/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5796 - rmse: 0.2292\n",
      "Epoch 19/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5797 - rmse: 0.2290\n",
      "Epoch 20/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5798 - rmse: 0.2290\n",
      "Epoch 21/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5805 - rmse: 0.2295\n",
      "Epoch 22/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5784 - rmse: 0.2280\n",
      "Epoch 23/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5793 - rmse: 0.2286TA: 0s - loss: 0.5793 - rmse:  - ETA: 0s - loss: 0.5793 - rmse\n",
      "Epoch 24/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5776 - rmse: 0.2271\n",
      "Epoch 25/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5778 - rmse: 0.22721s - loss: 0.5778 - rm\n",
      "Epoch 26/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5768 - rmse: 0.2265\n",
      "Epoch 27/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5761 - rmse: 0.22620s -\n",
      "Epoch 28/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5770 - rmse: 0.2268\n",
      "Epoch 29/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5763 - rmse: 0.2267\n",
      "Epoch 30/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5749 - rmse: 0.22542s - loss: 0.5747 -  - ETA: 1s - l - E\n",
      "Epoch 31/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5749 - rmse: 0.2258\n",
      "Epoch 32/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5747 - rmse: 0.2257 - ETA: 0s - loss: 0.5747 - rmse: 0.\n",
      "Epoch 33/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5742 - rmse: 0.2252\n",
      "Epoch 34/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5737 - rmse: 0.2250\n",
      "Epoch 35/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5736 - rmse: 0.22480s\n",
      "Epoch 36/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5733 - rmse: 0.2245\n",
      "Epoch 37/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5724 - rmse: 0.2241\n",
      "Epoch 38/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5720 - rmse: 0.2237\n",
      "Epoch 39/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5729 - rmse: 0.2243: 16s - loss: 0.5729 - rmse: 0. - ETA: 16s -\n",
      "Epoch 40/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5718 - rmse: 0.2235\n",
      "Epoch 41/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5715 - rmse: 0.22320s - loss: 0.5 - ETA: 0s - loss: 0.5715 \n",
      "Epoch 42/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5714 - rmse: 0.2232\n",
      "Epoch 43/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5716 - rmse: 0.2236\n",
      "Epoch 44/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5717 - rmse: 0.2234\n",
      "Epoch 45/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5718 - rmse: 0.2236\n",
      "Epoch 46/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5699 - rmse: 0.22191s - loss: 0\n",
      "Epoch 47/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5706 - rmse: 0.2227\n",
      "Epoch 48/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5701 - rmse: 0.2224\n",
      "Epoch 49/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5703 - rmse: 0.22230s - loss: 0.5703 - rmse: 0.\n",
      "Epoch 50/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5706 - rmse: 0.2226\n",
      "Epoch 51/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5701 - rmse: 0.2221\n",
      "Epoch 52/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5706 - rmse: 0.2226\n",
      "Epoch 53/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5704 - rmse: 0.2226\n",
      "Epoch 54/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5701 - rmse: 0.2222\n",
      "Epoch 55/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5702 - rmse: 0.2224\n",
      "Epoch 56/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5707 - rmse: 0.2225\n",
      "Epoch 57/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5707 - rmse: 0.2224\n",
      "Epoch 58/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5698 - rmse: 0.2220\n",
      "Epoch 59/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5703 - rmse: 0.2223\n",
      "Epoch 60/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5690 - rmse: 0.2212\n",
      "Epoch 61/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5698 - rmse: 0.2224: 18s - loss: 0.5676  - ETA: 18s\n",
      "Epoch 62/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5698 - rmse: 0.2219\n",
      "Epoch 63/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5693 - rmse: 0.22160s - loss: 0.569\n",
      "Epoch 64/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5693 - rmse: 0.2218\n",
      "Epoch 65/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5691 - rmse: 0.2214\n",
      "Epoch 66/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5693 - rmse: 0.2215\n",
      "Epoch 67/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5689 - rmse: 0.22140s -\n",
      "Epoch 68/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5680 - rmse: 0.2209\n",
      "Epoch 69/500\n",
      "1000/1000 [==============================] - 26s 26ms/step - loss: 0.5687 - rmse: 0.2210\n",
      "Epoch 70/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5686 - rmse: 0.22110s - loss: - ETA: 0s - loss: 0.5686 - rmse: 0.\n",
      "Epoch 71/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5694 - rmse: 0.2218\n",
      "Epoch 72/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5694 - rmse: 0.2220\n",
      "Epoch 73/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5680 - rmse: 0.2208\n",
      "Epoch 74/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5689 - rmse: 0.22140s - loss: 0.568 - ETA: 0s - loss: 0.5688 -  - ETA: 0s - loss: 0.5689 - rmse: 0.22\n",
      "Epoch 75/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5691 - rmse: 0.2213\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5689 - rmse: 0.2215\n",
      "Epoch 77/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5682 - rmse: 0.2208\n",
      "Epoch 78/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5691 - rmse: 0.22110s - loss: 0\n",
      "Epoch 79/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5688 - rmse: 0.2210\n",
      "Epoch 80/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5678 - rmse: 0.22070s\n",
      "Epoch 81/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5682 - rmse: 0.2204\n",
      "Epoch 82/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5678 - rmse: 0.2207\n",
      "Epoch 83/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5681 - rmse: 0.2207\n",
      "Epoch 84/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5688 - rmse: 0.2213\n",
      "Epoch 85/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5693 - rmse: 0.2216\n",
      "Epoch 86/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5684 - rmse: 0.2209\n",
      "Epoch 87/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5691 - rmse: 0.2213\n",
      "Epoch 88/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5684 - rmse: 0.22100s - loss: 0.5684 - rmse: 0.22\n",
      "Epoch 89/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5684 - rmse: 0.2211\n",
      "Epoch 90/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5693 - rmse: 0.22140s - loss: 0.5692 \n",
      "Epoch 91/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5676 - rmse: 0.2203\n",
      "Epoch 92/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5696 - rmse: 0.2219\n",
      "Epoch 93/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5683 - rmse: 0.2208\n",
      "Epoch 94/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5672 - rmse: 0.2199\n",
      "Epoch 95/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5672 - rmse: 0.2202\n",
      "Epoch 96/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5679 - rmse: 0.2206\n",
      "Epoch 97/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5677 - rmse: 0.2204\n",
      "Epoch 98/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5677 - rmse: 0.22034s - loss: 0.567\n",
      "Epoch 99/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5676 - rmse: 0.22030s -\n",
      "Epoch 100/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5674 - rmse: 0.2199\n",
      "Epoch 101/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5671 - rmse: 0.2199\n",
      "Epoch 102/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5667 - rmse: 0.2195\n",
      "Epoch 103/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5667 - rmse: 0.21960s - loss: 0.5667 - rmse\n",
      "Epoch 104/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5674 - rmse: 0.2200\n",
      "Epoch 105/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5669 - rmse: 0.2197\n",
      "Epoch 106/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5673 - rmse: 0.2203\n",
      "Epoch 107/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5670 - rmse: 0.2199\n",
      "Epoch 108/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5675 - rmse: 0.2205\n",
      "Epoch 109/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5679 - rmse: 0.2202\n",
      "Epoch 110/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5670 - rmse: 0.2198\n",
      "Epoch 111/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5674 - rmse: 0.22010s - loss: 0.5675 - rm\n",
      "Epoch 112/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5666 - rmse: 0.2192\n",
      "Epoch 113/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5675 - rmse: 0.2202\n",
      "Epoch 114/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5674 - rmse: 0.22011s - ETA: 0s - l\n",
      "Epoch 115/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5670 - rmse: 0.21974s - l -\n",
      "Epoch 116/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5665 - rmse: 0.21950s - loss: 0.566\n",
      "Epoch 117/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5665 - rmse: 0.21900s -\n",
      "Epoch 118/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5673 - rmse: 0.2199\n",
      "Epoch 119/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5665 - rmse: 0.2195\n",
      "Epoch 120/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5672 - rmse: 0.21993s\n",
      "Epoch 121/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5666 - rmse: 0.21970s - loss: 0\n",
      "Epoch 122/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5666 - rmse: 0.2196: \n",
      "Epoch 123/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5663 - rmse: 0.2192\n",
      "Epoch 124/500\n",
      "1000/1000 [==============================] - 24s 24ms/step - loss: 0.5662 - rmse: 0.2193\n",
      "Epoch 125/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5671 - rmse: 0.2197\n",
      "Epoch 126/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5657 - rmse: 0.21880s - l\n",
      "Epoch 127/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5674 - rmse: 0.2202\n",
      "Epoch 128/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5656 - rmse: 0.2188\n",
      "Epoch 129/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5675 - rmse: 0.2203\n",
      "Epoch 130/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5675 - rmse: 0.2201\n",
      "Epoch 131/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5668 - rmse: 0.2198\n",
      "Epoch 132/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5664 - rmse: 0.2190\n",
      "Epoch 133/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5663 - rmse: 0.21930s - loss: 0.566\n",
      "Epoch 134/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5669 - rmse: 0.2198\n",
      "Epoch 135/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5659 - rmse: 0.2188\n",
      "Epoch 136/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5667 - rmse: 0.2196\n",
      "Epoch 137/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5666 - rmse: 0.2194\n",
      "Epoch 138/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5667 - rmse: 0.2194\n",
      "Epoch 139/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2189\n",
      "Epoch 140/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5659 - rmse: 0.2189\n",
      "Epoch 141/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5668 - rmse: 0.2198\n",
      "Epoch 142/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5656 - rmse: 0.2185\n",
      "Epoch 143/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.2177\n",
      "Epoch 144/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5653 - rmse: 0.21884s - los -\n",
      "Epoch 145/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2187\n",
      "Epoch 146/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5656 - rmse: 0.21880s - loss: 0.5656 - rmse: 0.21\n",
      "Epoch 147/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5653 - rmse: 0.2186\n",
      "Epoch 148/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5662 - rmse: 0.21931s - loss: -\n",
      "Epoch 149/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5661 - rmse: 0.2192\n",
      "Epoch 150/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2188\n",
      "Epoch 151/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2183\n",
      "Epoch 152/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5647 - rmse: 0.2184\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2187\n",
      "Epoch 154/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5652 - rmse: 0.2185\n",
      "Epoch 155/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2188\n",
      "Epoch 156/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5657 - rmse: 0.2188\n",
      "Epoch 157/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5653 - rmse: 0.2189\n",
      "Epoch 158/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5665 - rmse: 0.2196\n",
      "Epoch 159/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.21860s - loss: 0.5656 - rmse:  - ETA: 0s - loss:\n",
      "Epoch 160/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5647 - rmse: 0.2181\n",
      "Epoch 161/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5657 - rmse: 0.2187\n",
      "Epoch 162/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5654 - rmse: 0.21870s - loss: 0.5653 - rmse: 0. - ETA: 0s - loss: 0.5653 - rmse: \n",
      "Epoch 163/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.21750s - loss:\n",
      "Epoch 164/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5649 - rmse: 0.2184\n",
      "Epoch 165/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5649 - rmse: 0.21830s - loss: 0.5648 \n",
      "Epoch 166/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2181\n",
      "Epoch 167/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5650 - rmse: 0.21835s - loss: -\n",
      "Epoch 168/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2187: 1s - loss: 0.5655  - ETA: 0s - loss: 0.5655 -  - ETA: 0s - loss: 0.5654 - \n",
      "Epoch 169/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5649 - rmse: 0.21800s - l\n",
      "Epoch 170/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5641 - rmse: 0.21762s - loss: 0.564 - ETA: 0s - loss: 0.5640 \n",
      "Epoch 171/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2189: 19s - loss: 0.5 - ETA: 15s - loss: 0.5653 - - ETA: 15s  - ETA: 13s - loss:  -  - ETA: 1s - loss: 0.5\n",
      "Epoch 172/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5643 - rmse: 0.2179\n",
      "Epoch 173/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.21800s - loss: 0.5642 - rmse: 0.\n",
      "Epoch 174/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5659 - rmse: 0.2190\n",
      "Epoch 175/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2180\n",
      "Epoch 176/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5639 - rmse: 0.2174: 23s - loss: 0.5 - ETA: 13s - lo - ETA: 5s - ETA: 4s - loss: 0.563\n",
      "Epoch 177/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5650 - rmse: 0.2181: 12s - loss: 0.5652 - rms\n",
      "Epoch 178/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5649 - rmse: 0.21830s - loss: 0\n",
      "Epoch 179/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5647 - rmse: 0.2182: 20s - loss: 0.5624 - rmse:  - ETA: 20s - loss: 0.5620 - rmse: 0 - ETA: 20s - loss: 0.5623 - r - ETA: 19s - loss - - ETA: 12s - loss: 0.5643 - rmse:  - ETA: 6s - loss: 0.5644 -  - E - ETA: 2s - loss: 0.5649 - rm - ETA: 2s - loss:\n",
      "Epoch 180/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5648 - rmse: 0.21820s - loss: - ETA: 0s - loss: 0.5648 - rmse: 0.21\n",
      "Epoch 181/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5647 - rmse: 0.21816s - loss: 0.5647 - rm - ETA: 6s - loss: 0 - ETA - ETA: 0s - loss: 0.5647 - rm\n",
      "Epoch 182/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5640 - rmse: 0.21772s - loss: 0.563 - ETA\n",
      "Epoch 183/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5649 - rmse: 0.2183\n",
      "Epoch 184/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5641 - rmse: 0.2180: 17s - ETA: 15s - loss: 0.56\n",
      "Epoch 185/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5653 - rmse: 0.2183: 16s - loss: 0.5659 - rmse: 0.218 - ETA: 15s - loss: 0.5660 - rmse: 0.2 - ETA: 15s -  - ETA: 14s - loss:  - ETA: 12s - loss: 0.5656  - ETA - ETA: 1s - loss: 0.565 -\n",
      "Epoch 186/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2178\n",
      "Epoch 187/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5643 - rmse: 0.2179\n",
      "Epoch 188/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5645 - rmse: 0.2179\n",
      "Epoch 189/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5647 - rmse: 0.2180A: 18s - loss: 0.5655 - rmse: 0.2 - ETA: 17s - loss: 0.5657  - ETA: 14s - loss: 0.5650 - rmse: 0.218 - ETA: 14s - loss: 0.5650 - rmse: 0.217 - ETA: 14s - loss: 0. - E - - ETA: 4s - loss: 0.563 - ETA: 4s - loss: 0.5641 - rmse: 0.21 - ETA: 4s - ETA: 3s - loss: 0 - ETA: 1s - loss: 0.5645 - rmse -\n",
      "Epoch 190/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5649 - rmse: 0.2182: 22s - loss: 0.5640 - rmse:  - ETA: 21s - loss: 0.5639  - ETA: 17s - loss: 0.5641 - rmse: 0.21 - ETA: 17s - loss: - ETA: 2s - los\n",
      "Epoch 191/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5645 - rmse: 0.2179\n",
      "Epoch 192/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5643 - rmse: 0.2179\n",
      "Epoch 193/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5650 - rmse: 0.21840s - los\n",
      "Epoch 194/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5644 - rmse: 0.2177: 1 - ETA: 5s - loss: 0.5 - ETA: 3s - l - ETA: 1s - loss: 0.564\n",
      "Epoch 195/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5636 - rmse: 0.2174: 20s - l - ETA: 3s - loss: - ETA: 2s - loss: 0.5636 - rm\n",
      "Epoch 196/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2180\n",
      "Epoch 197/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5638 - rmse: 0.2177\n",
      "Epoch 198/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5637 - rmse: 0.2173\n",
      "Epoch 199/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5645 - rmse: 0.21820s - los\n",
      "Epoch 200/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5650 - rmse: 0.2184\n",
      "Epoch 201/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2181\n",
      "Epoch 202/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5644 - rmse: 0.2180\n",
      "Epoch 203/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5644 - rmse: 0.2177\n",
      "Epoch 204/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.21760s - loss: 0.5643 - \n",
      "Epoch 205/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5643 - rmse: 0.2176\n",
      "Epoch 206/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.21771s - los - ETA: 0s - loss: 0.5641 - rmse:  - ETA: 0s - loss: 0.5\n",
      "Epoch 207/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5634 - rmse: 0.2170\n",
      "Epoch 208/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5654 - rmse: 0.2189\n",
      "Epoch 209/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5634 - rmse: 0.2172: 22s - loss: 0.5 - ETA: 21s - loss: - ETA: 0s - loss: 0.5633 - rmse: 0. - ETA: 0s - loss: 0.5633 - rm\n",
      "Epoch 210/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5638 - rmse: 0.2175\n",
      "Epoch 211/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.2177\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5644 - rmse: 0.2178: 30s - loss: 0.5626 - rmse - ETA: 26s - loss: 0 - ETA: 23s - loss: - -  - ETA: 8s - loss: 0.5640 - rmse: \n",
      "Epoch 213/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5639 - rmse: 0.2175\n",
      "Epoch 214/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5640 - rmse: 0.2178\n",
      "Epoch 215/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5646 - rmse: 0.2178\n",
      "Epoch 216/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5638 - rmse: 0.21731s - loss: 0.5638 - rmse: 0.21 - ETA: 1s - loss: 0.5638  - ETA: 0s - loss: 0.5 - ETA: 0s - loss: 0.5638 - rmse: \n",
      "Epoch 217/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5635 - rmse: 0.2171\n",
      "Epoch 218/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5634 - rmse: 0.21691s - loss: 0.5635 - rmse:  - ETA: 1s - - ETA: 0s - loss: 0.5634 - rm\n",
      "Epoch 219/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5633 - rmse: 0.2173\n",
      "Epoch 220/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5635 - rmse: 0.2172: 23s - lo - ETA: 21s - loss: 0.5645 - rmse: 0.2 - ETA: 21s - loss: 0 - ETA: 1s - loss: 0.563\n",
      "Epoch 221/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5638 - rmse: 0.21742s - ETA: 1s - ETA: 0s -\n",
      "Epoch 222/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5637 - rmse: 0.2171\n",
      "Epoch 223/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5653 - rmse: 0.2182: 19s - loss: 0.5663 - rmse:  - ETA: \n",
      "Epoch 224/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5633 - rmse: 0.2170\n",
      "Epoch 225/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5639 - rmse: 0.2176\n",
      "Epoch 226/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5643 - rmse: 0.21780s - loss: 0.5642 - rmse\n",
      "Epoch 227/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5640 - rmse: 0.21772s - loss: 0.5635  - ETA\n",
      "Epoch 228/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5631 - rmse: 0.2170\n",
      "Epoch 229/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5637 - rmse: 0.2174\n",
      "Epoch 230/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5639 - rmse: 0.2173: 30s - loss: 0.5648 - rmse: 0. - ETA: 27s - l - ETA: 23s - loss - ETA: 21s - loss: 0.5645 - rmse: 0.21 - ETA: 21s - loss: 0.5642 - - ETA: 14s - loss: 0.5643 - rmse: 0.2 - ETA: 14s - loss: 0.5644 - rmse: 0.2 - ETA: 14s - loss: 0.5644 - rmse:  - E - ET\n",
      "Epoch 231/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5633 - rmse: 0.2172\n",
      "Epoch 232/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5637 - rmse: 0.2172\n",
      "Epoch 233/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5637 - rmse: 0.2170\n",
      "Epoch 234/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5642 - rmse: 0.2178\n",
      "Epoch 235/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5655 - rmse: 0.2188\n",
      "Epoch 236/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5636 - rmse: 0.2173\n",
      "Epoch 237/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5622 - rmse: 0.2164\n",
      "Epoch 238/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5627 - rmse: 0.21650s - loss: 0.5626 \n",
      "Epoch 239/500\n",
      "1000/1000 [==============================] - 25s 25ms/step - loss: 0.5640 - rmse: 0.2171: 1 - - ETA: 12s  - ETA: 7s - loss:\n",
      "Epoch 240/500\n",
      " 315/1000 [========>.....................] - ETA: 17s - loss: 0.5633 - rmse: 0.2166- ETA: 22s - loss: 0.5628 - rmse - ETA: 19s - loss: 0.5632 - rmse - ETA: 18s - loss"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-135-4df5136929c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbalancedBatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2222\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2223\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2224\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(balancedBatch,steps_per_epoch=1000,epochs=500,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26803568754821827"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(select_val_scaled)\n",
    "true = select_val[\"deal_probability\"]\n",
    "math.sqrt(mean_squared_error(true,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2627653092426415"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean = select_train[\"deal_probability\"].mean()\n",
    "pred = np.full(select_val[\"deal_probability\"].shape,train_mean )\n",
    "true = select_val[\"deal_probability\"]\n",
    "math.sqrt(mean_squared_error(true,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261417,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_val[\"deal_probability\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
