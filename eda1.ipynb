{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0179ac23-00f2-458d-9956-eb709943c113",
    "_uuid": "9f4d33ca7540d370b63577940e36139c2c299fb1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "37b28625-ffaf-46d8-8a49-0245dd570eaa",
    "_uuid": "28ddec29297930bc265ab367796fb507414ac64a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv(\"../input/sample_submission.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "43dd66ee-3d5c-4d48-9469-b79fc42a30d1",
    "_uuid": "39703715119b6aa28c8dd5839f2e8715f387be42"
   },
   "source": [
    "Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f8bdce40-1680-4bb9-ad33-d80a063589df",
    "_uuid": "b1adf8a2c21b6af007e7660a67542c6533e36d39",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv(\"../input/train.csv\")\n",
    "testDF = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "#trainDF.head()\n",
    "testDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c6a8cd34-d260-48aa-b83a-8f8ebc691b79",
    "_uuid": "2baf704478db173991dc2650c8ee2b2acb97a882"
   },
   "source": [
    "Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "361d7d75-eadf-4125-96d3-aac22673118c",
    "_uuid": "facd5a687e3bec1ad5f095f93473801708143fad",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainDF = trainDF[[\"description\",\"price\",\"title\",\"city\",\"category_name\",\"deal_probability\"]].dropna(axis=0, how='any')[0:100000]\n",
    "testDF = testDF[[\"item_id\",\"price\",\"title\",\"city\",\"category_name\",\"description\"]].fillna(0)\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "# Description \n",
    "tokenizer.fit_on_texts(trainDF[\"description\"])\n",
    "\n",
    "trainDF[\"description\"] = tokenizer.texts_to_sequences(trainDF[\"description\"])\n",
    "testDF[\"description\"]  = tokenizer.texts_to_sequences(testDF[\"description\"])\n",
    "\n",
    "train_x = pad_sequences(trainDF[\"description\"], maxlen=maxlen)\n",
    "test_x = pad_sequences(testDF[\"description\"], maxlen=maxlen)\n",
    "\n",
    "# Title \n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(trainDF[\"title\"])\n",
    "\n",
    "trainDF[\"title\"] = tokenizer.texts_to_sequences(trainDF[\"title\"])\n",
    "testDF[\"title\"]  = tokenizer.texts_to_sequences(testDF[\"title\"])\n",
    "\n",
    "train_title = pad_sequences(trainDF[\"title\"], maxlen=maxlen)\n",
    "test_title = pad_sequences(testDF[\"title\"], maxlen=maxlen)\n",
    "\n",
    "# Category\n",
    "trainDF['category_name'], mapping_index_category = pd.Series(trainDF['category_name']).factorize()\n",
    "reverseCatMap = {mapping_index_category[i]: i for i in range(0, len(mapping_index_category))}\n",
    "testDF['category_name'] = testDF['category_name'].map(reverseCatMap)\n",
    "\n",
    "# City\n",
    "trainDF['city'], mapping_index_city = pd.Series(trainDF['city']).factorize()\n",
    "reverseCityMap = {mapping_index_city[i]: i for i in range(0, len(mapping_index_city))}\n",
    "testDF['city'] = testDF['city'].map(reverseCityMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "67b77f98-ab07-4d09-8868-f207d4f3bfcd",
    "_uuid": "ef937d81636ad30d5cee311b7c2ee2f02d8dabaa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation,Concatenate\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "embed_size = 128\n",
    "inp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = LSTM(100, return_sequences=True,name='lstm_layer')(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "embed_size = 128\n",
    "titleInp = Input(shape=(maxlen, )) #maxlen=200 as defined earlier\n",
    "y = Embedding(max_features, embed_size)(titleInp)\n",
    "y = LSTM(100, return_sequences=True,name='lstm_layer2')(y)\n",
    "y = GlobalMaxPool1D()(y)\n",
    "y = Dropout(0.1)(y)\n",
    "\n",
    "x = Concatenate(axis=-1)([x,y])\n",
    "\n",
    "x = Dense(300, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(100, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "priceInp = Input(shape=(1, ))\n",
    "catInp = Input(shape=(1, ))\n",
    "cityInp = Input(shape=(1, ))\n",
    "\n",
    "x = Concatenate(axis=-1)([x,priceInp,catInp,cityInp])\n",
    "x = Dense(50, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=[inp,titleInp,priceInp,catInp,cityInp], outputs=x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "42393589-d434-481e-852f-3e640b8e4c5b",
    "_uuid": "b2fd616e771fcc4c14b9248e901ab4a399619e62",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit([train_x,train_title,trainDF[\"price\"],trainDF[\"category_name\"],trainDF[\"city\"]],trainDF[[\"deal_probability\"]],epochs=5, batch_size=300,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f92e5fc1-61eb-49ec-8db0-c861cf0cd58e",
    "_uuid": "3e46c69960ba9bb33f5a0560f4606f37adeb164a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modelPred = model.predict([test_x[0:10],testDF[\"price\"]],batch_size=300).reshape(10)\n",
    "modelPred = model.predict([test_x,testDF[\"price\"],testDF[\"category_name\"]],batch_size=300).reshape(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f427dd3-2d98-4501-8d71-5b45475b94f0",
    "_uuid": "9cc3bfcef89fc117a92101c96bc2b73afc5e84bf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_to_submit = pd.DataFrame.from_items([\n",
    "    ('item_id',testDF[\"item_id\"]),\n",
    "    ('deal_probability', pd.Series(modelPred))])\n",
    "\n",
    "data_to_submit.to_csv('csv_to_submit.csv', index = False)\n",
    "\n",
    "#data_to_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fd2170e7-6dae-4162-91a4-18dc93998697",
    "_uuid": "ad655632ba24fc9672a8b7a654b81fc2a24789ba",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#resDF['category_name'] = resDF['category_name'].astype('category')\n",
    "#resDF['category_name'], mapping_index_category = pd.Series(resDF['category_name']).factorize()\n",
    "#resDF['city'], mapping_index_city = pd.Series(resDF['city']).factorize()\n",
    "#resDF = resDF.dropna(axis=0, how='any')\n",
    "#resDF[\"description\"] = resDF[\"description\"].map(lambda z: len(z))\n",
    "#resDF[[\"price\"]] /= resDF[[\"price\"]].max()\n",
    "#resDF[[\"price\",\"category_name\",\"description\"]] /= resDF[[\"price\",\"category_name\",\"description\"]].max()\n",
    "#plt.matshow(trainDF[[\"price\",\"category_name\",\"city\",\"deal_probability\"]].corr())\n",
    "#plt.show()\n",
    "#plt.subplots(figsize=(10,10))\n",
    "#corr = resDF.corr()\n",
    "#sns.heatmap(corr, \n",
    "#            xticklabels=corr.columns.values,\n",
    "#            yticklabels=corr.columns.values,)\n",
    "#enc = OneHotEncoder()\n",
    "#catList = [ [i] for i in range(0, len(mapping_index_category))]\n",
    "#enc.fit(catList)\n",
    "\n",
    "#train_cat_onehot = enc.transform(np.array(trainDF['category_name'].data).reshape(-1,1)).toarray()\n",
    "#test_cat_onehot = enc.transform(np.array(testDF['category_name'].data).reshape(-1,1)).toarray()\n",
    "#trainDF['category_name'] = trainDF['category_name'].map(lambda x : enc.transform([[x]]).toarray())\n",
    "\n",
    "\n",
    "#testDF['category_name'] = testDF['category_name'].map(lambda x : enc.transform([[reverseCatMap[x]]]).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
