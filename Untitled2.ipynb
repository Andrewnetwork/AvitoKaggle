{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andre\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras import backend\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact_manual\n",
    "import os\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical,Sequence\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.read_csv(\"./input/avito-demand-prediction/test.csv\")\n",
    "trainDF = pd.read_csv(\"./input/avito-demand-prediction/train.csv\")\n",
    "\n",
    "trainDF[\"description\"] = trainDF[\"description\"].fillna(\"\")\n",
    "trainDF[\"title\"] = trainDF[\"title\"].fillna(\"\")\n",
    "trainDF = trainDF.fillna(0)\n",
    "\n",
    "testDF[\"description\"] = testDF[\"description\"].fillna(\"\")\n",
    "testDF[\"title\"] = testDF[\"title\"].fillna(\"\")\n",
    "testDF = testDF.fillna(0)\n",
    "\n",
    "# Preprocessing\n",
    "trainDF[\"activation_date\"] = pd.to_datetime(trainDF[\"activation_date\"])\n",
    "testDF[\"activation_date\"] = pd.to_datetime(testDF[\"activation_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load( open( \"scaler_5_27_18_1.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeats = [\"region\",\"city\",\"category_name\",\"parent_category_name\",\"user_type\",\"activation_date\"]\n",
    "quantFeats = [\"price\",\"description\",\"title\",\"image_top_1\",\"item_seq_number\"]\n",
    "targetFeat = [\"deal_probability\"]\n",
    "feats = categoricalFeats + quantFeats\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 200\n",
    "\n",
    "def codexLookup(cats,inStr):\n",
    "    if(inStr in cats):\n",
    "        return int(np.where(cats==inStr)[0][0])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def toCode(df,category,codex,uList):\n",
    "    return df[category].map(lambda x: codex[category](uList[category],x))\n",
    "\n",
    "def getCatSizes(df,catFeats):\n",
    "    lenDict = {}\n",
    "    codex = {}\n",
    "    uniqueLists = {}\n",
    "    for feat in catFeats:\n",
    "        cats = df[feat].unique()\n",
    "        uniqueLists[feat] =  cats \n",
    "        lenDict[feat] = cats.shape[0]\n",
    "        codex[feat] = lambda refDict,inStr : codexLookup(refDict,inStr)\n",
    "    \n",
    "    return lenDict,uniqueLists,codex\n",
    " \n",
    "def preprocessDat(df,catSizes,codex,uList):\n",
    "    # Convert categorical variables to one-hot vectors. \n",
    "    catFeats = []\n",
    "    \n",
    "    for cat in catSizes:\n",
    "        catFeats.append(to_categorical(toCode(df,cat,codex,uList),num_classes=catSizes[cat]))\n",
    "    \n",
    "    # Further preprocessing. \n",
    "    df[\"description\"] = df[\"description\"].map(len)\n",
    "    df[\"title\"] = df[\"title\"].map(len)\n",
    "    \n",
    "    df = df.drop(categoricalFeats,axis=1)\n",
    "    \n",
    "    df = df.replace('', 0, regex=True)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    \n",
    "    return  df,catFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andre\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Andre\\Anaconda3\\envs\\GreatEnv\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Categorical Category Sizes\n",
    "catSizes,uList,codex = getCatSizes(trainDF,categoricalFeats)\n",
    "\n",
    "test_quant,test_categorical = preprocessDat(testDF[feats],catSizes,codex,uList)\n",
    "test_quant_scaled = scaler.transform(test_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "model = load_model(\"5_25_18_OneHotCatAndQuant_10.h5\",{\"rmse\":rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict([test_quant_scaled]+test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_submit = pd.DataFrame.from_items([\n",
    "    ('item_id',testDF[\"item_id\"]),\n",
    "    ('deal_probability', pd.Series(np.hstack(pred)))])\n",
    "\n",
    "data_to_submit.to_csv('5_25_18_submit_11.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
